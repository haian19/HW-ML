{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install pyvi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuuxIv-WBeON",
        "outputId": "ee3b2db4-9e71-436a-e8a2-22eb1a1653f4"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyvi in /usr/local/lib/python3.10/dist-packages (0.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from pyvi) (1.3.2)\n",
            "Requirement already satisfied: sklearn-crfsuite in /usr/local/lib/python3.10/dist-packages (from pyvi) (0.5.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pyvi) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pyvi) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pyvi) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pyvi) (3.5.0)\n",
            "Requirement already satisfied: python-crfsuite>=0.9.7 in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite->pyvi) (0.9.10)\n",
            "Requirement already satisfied: tabulate>=0.4.2 in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite->pyvi) (0.9.0)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite->pyvi) (4.66.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.datasets import load_files\n",
        "from pyvi import ViTokenizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "o5qQED3kBkVJ"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip news.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7k7XgryfVuG",
        "outputId": "20e3f84c-4480-477c-e482-3bb41b864d92"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  news.zip\n",
            "replace news_1135/Giải trí/00a00d8f63505813279de920ee6b0e364fdbf062.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT = '/content/news_1135'\n",
        "os.makedirs(\"images\",exist_ok=True)  # thư mục lưu các các hình ảnh trong quá trình huấn luyện và đánh gía"
      ],
      "metadata": {
        "id": "suZst7CBBp5-"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# statistics\n",
        "print('Các nhãn và số văn bản tương ứng trong dữ liệu')\n",
        "print('----------------------------------------------')\n",
        "n = 0\n",
        "for label in os.listdir(INPUT):\n",
        "    print(f'{label}: {len(os.listdir(os.path.join(INPUT, label)))}')\n",
        "    n += len(os.listdir(os.path.join(INPUT, label)))\n",
        "\n",
        "print('-------------------------')\n",
        "print(f\"Tổng số văn bản: {n}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdwwIVZkZpOJ",
        "outputId": "759ba1da-f0f4-4925-bf07-19eb5b4780f2"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Các nhãn và số văn bản tương ứng trong dữ liệu\n",
            "----------------------------------------------\n",
            "Thời sự: 138\n",
            "Kinh tế: 186\n",
            "Thể thao: 140\n",
            "Giải trí: 107\n",
            "Sức khỏe: 75\n",
            "Khoa học - Công nghệ: 196\n",
            "Độc giả: 52\n",
            "Pháp luật: 50\n",
            "Đời sống - Xã hội: 91\n",
            "Tin khác: 100\n",
            "-------------------------\n",
            "Tổng số văn bản: 1135\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load data\n",
        "data_train = load_files(container_path=INPUT, encoding=\"utf-8\")\n",
        "print('mapping:')\n",
        "for i in range(len(data_train.target_names)):\n",
        "    print(f'{data_train.target_names[i]} - {i}')\n",
        "\n",
        "print('--------------------------')\n",
        "print(data_train.filenames[0:1])\n",
        "# print(data_train.data[0:1])\n",
        "print(data_train.target[0:1])\n",
        "print(data_train.data[0:1])\n",
        "\n",
        "print(\"\\nTổng số  văn bản: {}\" .format( len(data_train.filenames)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2ZQA4HRhRth",
        "outputId": "d3a43d3c-712e-44c1-db7f-35fc8fd7b996"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mapping:\n",
            "Giải trí - 0\n",
            "Khoa học - Công nghệ - 1\n",
            "Kinh tế - 2\n",
            "Pháp luật - 3\n",
            "Sức khỏe - 4\n",
            "Thể thao - 5\n",
            "Thời sự - 6\n",
            "Tin khác - 7\n",
            "Đời sống - Xã hội - 8\n",
            "Độc giả - 9\n",
            "--------------------------\n",
            "['/content/news_1135/Tin khác/0218e1df21ce358b9c6485176a48f1fcaeedef67.txt']\n",
            "[7]\n",
            "['Dân_trí Sở GD & ĐT tỉnh Gia_Lai vừa ra văn_bản số 2258 / SGDĐT - VP , về việc chấn_chỉnh việc tiếp_thị sách và các vật_dụng khác trong các cơ_sở giáo_dục . Văn_bản chỉ_đạo , tuyệt_đối không cho phép các cá_nhân , tập_thể đến trường tiếp_thị , quảng_cáo mua_bán sách , dụng_cụ học_tập … cho giáo_viên và học_sinh trong nhà_trường . Các tổ_chức , cá_nhân trong ngành giáo_dục tuyệt_đối không được thực_hiện hoặc tham_gia giới_thiệu , quảng_bá , vận_động mua , phát_hành sách tham_khảo tới học_sinh hoặc phụ_huynh dưới hình_thức nào . Nhà_trường tuyệt_đối không được lưu_hành , sử_dụng sách có nội_dung không lành_mạnh , không phù_hợp với nội_dung chương_trình phổ_thông . Trường_hợp phát_hiện sách có sai_sót , các đơn_vị cần báo_cáo với cấp trên để có hướng xử_lý . Các sơ sở giáo_dục đề_cao cảnh_giác đối_với trường_hợp mạo_danh cán_bộ , chuyên_viên sở trong ngành đi giới_thiệu sách , đồ_dùng học_sinh ; công_khai phổ_biến các quy_định trên đến cán_bộ , giáo_viên , học_sinh để cùng phòng tránh và ngăn_chặn … Trước đó , báo Dân_trí đã thông_tin về việc học_sinh của Trường Tiểu_học số 2 xã Hòa Phú ( Chư_Păh , Gia_Lai ) đã mang 1 tờ giấy thông_báo về việc mua sách tham_khảo mang về cho phụ_huynh và xin tiền để mua sách , khiến nhiều phụ_huynh bức_xúc . Sự_việc được bà Dương Thị Nga - Hiệu_trưởng nhà_trường cho biết , do hôm xảy ra sự_việc , bà đi_vắng nên không hay_biết . Tuệ Mẫn']\n",
            "\n",
            "Tổng số  văn bản: 1135\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load dữ liệu các stopwords\n",
        "vn_stopwords = ['a_lô', 'a_ha', 'ai', 'ai_ai', 'ai_nấy', 'ai_đó', 'alô', 'amen', 'anh', 'anh_ấy']\n",
        "\n",
        "# Chuyển hoá dữ liệu text về dạng vector TF\n",
        "#     - loại bỏ từ dừng\n",
        "#     - sinh từ điển\n",
        "\n",
        "#remove stopwords:\n",
        "data_train_no_sw = [] #store data cleaned\n",
        "count = 0\n",
        "for doc in data_train.data:\n",
        "  words = doc.split()\n",
        "  filtered_words = []\n",
        "  for word in words:\n",
        "    if word in vn_stopwords:\n",
        "      count+=1\n",
        "    else:\n",
        "      filtered_words.append(word)\n",
        "  filtered_doc = ' '.join(filtered_words)\n",
        "  data_train_no_sw.append(filtered_doc)\n",
        "data_train.data = data_train_no_sw\n",
        "print(f\"so luong stopwords: {count}\")\n",
        "\n",
        "#generate dictionary\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Hàm thực hiện chuyển đổi dữ liệu text thành dữ liệu số dạng ma trận\n",
        "# Input: Dữ liệu 2 chiều dạng numpy.array, mảng nhãn id dạng numpy.array\n",
        "\n",
        "data_preprocessed = vectorizer.fit_transform(data_train.data)\n",
        "\n",
        "X = data_preprocessed # thuoc tinh\n",
        "Y = data_train.target #nhan\n",
        "\n",
        "print(f\"\\nSố lượng từ trong từ điển: {len(vectorizer.vocabulary_)}\")\n",
        "print(f\"Kích thước dữ liệu sau khi xử lý: {X.shape}\")\n",
        "print(f\"Kích thước nhãn tương ứng: {Y.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kd4qA0yOh_7f",
        "outputId": "ab296b0a-25ae-404c-8029-e87139cab74f"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "so luong stopwords: 1134\n",
            "\n",
            "Số lượng từ trong từ điển: 25198\n",
            "Kích thước dữ liệu sau khi xử lý: (1135, 25198)\n",
            "Kích thước nhãn tương ứng: (1135,)\n"
          ]
        }
      ]
    }
  ]
}